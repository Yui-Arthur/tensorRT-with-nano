{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a7RBVllTOCd"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Ym_co7Wsl2"
      },
      "source": [
        "## training yolov8 with dogs and cats dataset\n",
        "\n",
        "https://www.kaggle.com/datasets/andrewmvd/dog-and-cat-detection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt359aGMXSJ1"
      },
      "source": [
        "#### use kaggle api to download dataset\n",
        "\n",
        "#### upload kaggle api token to ``` ~/.kaggle/kaggle.json ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7vyugLmYjYQ",
        "outputId": "9aa61683-4f46-42d0-e558-1ed5b5b82b64"
      },
      "outputs": [],
      "source": [
        "# kaggle dowload if upload dataset skip this\n",
        "!pip install --user kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d andrewmvd/dog-and-cat-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClcEydIvH8RJ"
      },
      "outputs": [],
      "source": [
        "!unzip ./dog-and-cat-detection.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoRk8R2Ur6Ed"
      },
      "outputs": [],
      "source": [
        "yolo_class = {\n",
        "    0 : \"dog\",\n",
        "    1 : \"cat\"\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QEuI2FqQmtnd"
      },
      "source": [
        "### Convert Pascal VOC XML to Yolo txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqvdTa4wZDNN"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "def convert_label(path, lb_path):\n",
        "  def convert_box(size, box):\n",
        "    dw, dh = 1. / size[0], 1. / size[1]\n",
        "    x, y, w, h = (box[0] + box[1]) / 2.0 - 1, (box[2] + box[3]) / 2.0 - 1, box[1] - box[0], box[3] - box[2]\n",
        "    return x * dw, y * dh, w * dw, h * dh\n",
        "\n",
        "  in_file = open(path)\n",
        "  out_file = open(lb_path, 'w')\n",
        "  tree = ET.parse(in_file)\n",
        "  root = tree.getroot()\n",
        "  size = root.find('size')\n",
        "  w = int(size.find('width').text)\n",
        "  h = int(size.find('height').text)\n",
        "\n",
        "  names = [yolo_class[0] , yolo_class[1]] # names list\n",
        "  for obj in root.iter('object'):\n",
        "    cls = obj.find('name').text\n",
        "    if cls in names and int(obj.find('difficult').text) != 1:\n",
        "      xmlbox = obj.find('bndbox')\n",
        "      bb = convert_box((w, h), [float(xmlbox.find(x).text) for x in ('xmin', 'xmax', 'ymin', 'ymax')])\n",
        "      cls_id = names.index(cls)  # class id\n",
        "      out_file.write(\" \".join([str(a) for a in (cls_id, *bb)]) + '\\n')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce3djSwbsxAB"
      },
      "outputs": [],
      "source": [
        "path = Path(\"./yolo\")\n",
        "\n",
        "for dir in (\"train\" , \"valid\"):\n",
        "  imgs_path = path / dir / 'images'\n",
        "  lbs_path = path / dir / 'labels'\n",
        "  imgs_path.mkdir(exist_ok=True, parents=True)\n",
        "  lbs_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "train_valid_ratio = 0.9\n",
        "annotations = list(Path(\"./annotations/\").glob(\"*.xml\"))\n",
        "for idx , an_path in enumerate(annotations):\n",
        "  target_lb_path = path / 'train' / 'labels' if idx < train_valid_ratio * len(annotations) else path / 'valid' / 'labels'\n",
        "  target_img_path = path / 'train' / 'images' if idx < train_valid_ratio * len(annotations) else path / 'valid' / 'images'\n",
        "  lb_path = (target_lb_path / an_path.name).with_suffix('.txt')  # new label path\n",
        "  shutil.copy( (Path(\"./images\") / an_path.name).with_suffix('.png') , target_img_path)\n",
        "  convert_label(an_path, lb_path)  # convert labels to YOLO format"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DMPrHke0ANKL"
      },
      "source": [
        "### yolo train yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHhB7vGn8Ble"
      },
      "outputs": [],
      "source": [
        "yaml_file = \"\"\"\n",
        "path: /content/yolo\n",
        "train: train/images\n",
        "val: valid/images\n",
        "\n",
        "names:\n",
        " 0: dog\n",
        " 1: cat\n",
        "\"\"\"\n",
        "with open(\"dog_cat.yaml\" , 'w') as f:\n",
        "  f.write(yaml_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cud1hVoJYMXQ",
        "outputId": "2d1e38d6-e5b2-40b3-b895-40c7c38c4040"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dt8B0SCQdO-Y"
      },
      "source": [
        "#### CLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deXoZt6e-QE6",
        "outputId": "bde303a6-c111-40d0-da6c-5f95c74b0be4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_MODE\"]=\"offline\"\n",
        "!yolo detect train data=dog_cat.yaml model=yolov8n.pt epochs=10 imgsz=320"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KGsraJRgdSwM"
      },
      "source": [
        "#### python test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS7Yk3bxdT2j"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt')\n",
        "model.predict(\"/content/yolo/valid/images/Cats_Test1001.png\", save=True, imgsz=320, conf=0.5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "orpE2xr2aRNm"
      },
      "source": [
        "## export yolov8 to trt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myLH8_0ND6GR"
      },
      "outputs": [],
      "source": [
        "# your model path\n",
        "train_path = Path(\"/content/runs/detect/train\")\n",
        "model_path = train_path / \"weights\"\n",
        "pt_file = str(model_path / \"best.pt\")\n",
        "onnx_file = str(model_path / \"best.onnx\")\n",
        "trt_file = str(model_path / \"best.engine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kml-Warneajo"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download(train_path / \"results.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx8sSRFgYpCD",
        "outputId": "4ad76e12-9570-4943-f44a-d34daf9264df"
      },
      "outputs": [],
      "source": [
        "# onnx runtime\n",
        "!yolo export model={pt_file} format=onnx opset=16\n",
        "!mv {onnx_file} {onnx_file.replace(\".onnx\" , \"op16.onnx\")}\n",
        "\n",
        "# tensorRT engine\n",
        "!yolo export model={pt_file} format=onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uhrzUqWq9JrW",
        "outputId": "20a82901-7788-4752-972b-84e5b14e3fe6"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(onnx_file)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zeyiJxKaWf2f"
      },
      "source": [
        "### onnx to trt engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r06djutgYtu",
        "outputId": "421a6f84-84af-47d8-f0aa-4aae075fcb3b"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip install --upgrade tensorrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6Y8UGeZiUAz"
      },
      "outputs": [],
      "source": [
        "import tensorrt as trt\n",
        "\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
        "def build_engine(onnx_path, shape):\n",
        "\n",
        "   \"\"\"\n",
        "   This is the function to create the TensorRT engine\n",
        "   Args:\n",
        "      onnx_path : Path to onnx_file.\n",
        "      shape : Shape of the input of the ONNX file.\n",
        "  \"\"\"\n",
        "   with trt.Builder(TRT_LOGGER) as builder, builder.create_network(1) as network, builder.create_builder_config() as config, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
        "       config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 256 << 20)\n",
        "       with open(onnx_path, 'rb') as model:\n",
        "           parser.parse(model.read())\n",
        "       network.get_input(0).shape = shape\n",
        "       engine = builder.build_serialized_network(network, config)\n",
        "       return engine\n",
        "\n",
        "def save_engine(engine, file_name):\n",
        "  #  buf = engine.serialize()\n",
        "   with open(file_name, 'wb') as f:\n",
        "       f.write(engine)\n",
        "def load_engine(trt_runtime, plan_path):\n",
        "  with open(plan_path, 'rb') as f:\n",
        "    engine_data = f.read()\n",
        "  engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
        "  # engine = trt_runtime.deserialize_cuda_engine(Path(plan_path).read_bytes())\n",
        "  return engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Quryc8b4ic0O",
        "outputId": "a85d1413-e0ff-40b5-e972-7acd76336c46"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from onnx import ModelProto\n",
        "import tensorrt as trt\n",
        "\n",
        "engine_name = trt_file\n",
        "onnx_path = onnx_file\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "model = ModelProto()\n",
        "with open(onnx_path, \"rb\") as f:\n",
        "    model.ParseFromString(f.read())\n",
        "\n",
        "d0 = model.graph.input[0].type.tensor_type.shape.dim[1].dim_value\n",
        "d1 = model.graph.input[0].type.tensor_type.shape.dim[2].dim_value\n",
        "d2 = model.graph.input[0].type.tensor_type.shape.dim[3].dim_value\n",
        "shape = [batch_size , d0, d1 ,d2]\n",
        "engine = build_engine(onnx_path, shape= shape)\n",
        "save_engine(engine, engine_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9os3k9iqiJB",
        "outputId": "787c4c6d-1b6d-4cbc-c0d2-4509eb21dd8a"
      },
      "outputs": [],
      "source": [
        "output_0 = model.graph.output[0].type.tensor_type.shape.dim[0].dim_value\n",
        "output_1 = model.graph.output[0].type.tensor_type.shape.dim[1].dim_value\n",
        "output_2 = model.graph.output[0].type.tensor_type.shape.dim[2].dim_value\n",
        "model_output_shape = (output_0 , output_1 , output_2)\n",
        "print(model_output_shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cMYRsUH0aWXs"
      },
      "source": [
        "## tensorRT inference yolov8 engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V08kVfTa4Pb",
        "outputId": "a4dedef5-7b10-4908-bb3b-f81a0d009602"
      },
      "outputs": [],
      "source": [
        "!pip install pycuda\n",
        "!wget https://www.akc.org/wp-content/uploads/2021/07/Cavalier-King-Charles-Spaniel-laying-down-indoors.jpeg -O ./dog.jpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcyVovAMac-V"
      },
      "outputs": [],
      "source": [
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "\n",
        "def allocate_buffers(engine, batch_size, data_type):\n",
        "\n",
        "   \"\"\"\n",
        "   This is the function to allocate buffers for input and output in the device\n",
        "   Args:\n",
        "      engine : The path to the TensorRT engine.\n",
        "      batch_size : The batch size for execution time.\n",
        "      data_type: The type of the data for input and output, for example trt.float32.\n",
        "\n",
        "   Output:\n",
        "      h_input_1: Input in the host.\n",
        "      d_input_1: Input in the device.\n",
        "      h_output_1: Output in the host.\n",
        "      d_output_1: Output in the device.\n",
        "      stream: CUDA stream.\n",
        "\n",
        "   \"\"\"\n",
        "\n",
        "   # Determine dimensions and create page-locked memory buffers (which won't be swapped to disk) to hold host inputs/outputs.\n",
        "   tensor_name = engine.get_tensor_name(0)\n",
        "   h_input_1 = cuda.pagelocked_empty(trt.volume(engine.get_tensor_shape(tensor_name)), dtype=trt.nptype(data_type))\n",
        "   tensor_name = engine.get_tensor_name(1)\n",
        "   h_output = cuda.pagelocked_empty(trt.volume(engine.get_tensor_shape(tensor_name)), dtype=trt.nptype(data_type))\n",
        "\n",
        "   # Allocate device memory for inputs and outputs.\n",
        "   d_input_1 = cuda.mem_alloc(h_input_1.nbytes)\n",
        "\n",
        "   d_output = cuda.mem_alloc(h_output.nbytes)\n",
        "   # Create a stream in which to copy inputs/outputs and run inference.\n",
        "   stream = cuda.Stream()\n",
        "   return h_input_1, d_input_1, h_output, d_output, stream\n",
        "\n",
        "def load_images_to_buffer(pics, pagelocked_buffer):\n",
        "   preprocessed = np.asarray(pics).ravel()\n",
        "   np.copyto(pagelocked_buffer, preprocessed)\n",
        "\n",
        "def do_inference(engine, pics_1, h_input_1, d_input_1, h_output, d_output, stream, batch_size, height, width):\n",
        "   \"\"\"\n",
        "   This is the function to run the inference\n",
        "   Args:\n",
        "      engine : Path to the TensorRT engine\n",
        "      pics_1 : Input images to the model.\n",
        "      h_input_1: Input in the host\n",
        "      d_input_1: Input in the device\n",
        "      h_output_1: Output in the host\n",
        "      d_output_1: Output in the device\n",
        "      stream: CUDA stream\n",
        "      batch_size : Batch size for execution time\n",
        "      height: Height of the output image\n",
        "      width: Width of the output image\n",
        "\n",
        "   Output:\n",
        "      The list of output images\n",
        "\n",
        "   \"\"\"\n",
        "\n",
        "   load_images_to_buffer(pics_1, h_input_1)\n",
        "\n",
        "   with engine.create_execution_context() as context:\n",
        "      # Transfer input data to the GPU.\n",
        "      cuda.memcpy_htod_async(d_input_1, h_input_1, stream)\n",
        "\n",
        "      # Run inference.\n",
        "\n",
        "      context.profiler = trt.Profiler()\n",
        "      context.execute_v2(bindings=[int(d_input_1), int(d_output)])\n",
        "\n",
        "      # Transfer predictions back from the GPU.\n",
        "      cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
        "      # Synchronize the stream\n",
        "      stream.synchronize()\n",
        "      # Return the host output.\n",
        "      out = h_output.reshape((model_output_shape))\n",
        "      # out = h_output\n",
        "      return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8HnEuTpRr9S"
      },
      "outputs": [],
      "source": [
        "def draw_detect(img , x , y , width , height , conf , label):\n",
        "  # label = f'{CLASSES[class_id]} ({confidence:.2f})'\n",
        "  # color = colors[class_id]\n",
        "  print(x , y , width , height , conf , label)\n",
        "  cv2.rectangle(img, (x, y), (x + width, y + height), (0,0,255), 2)\n",
        "  cv2.putText(img, f\"{yolo_class[label]} {conf}\", (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
        "\n",
        "def show_detect(img , preds , threshold = 0.5):\n",
        "  boxes = []\n",
        "  scores = []\n",
        "  class_ids = []\n",
        "\n",
        "  for pred_idx in range(preds.shape[2]):\n",
        "    pred = preds[0,:,pred_idx]\n",
        "    box = [pred[0] - 0.5*pred[2] , pred[1] - 0.5*pred[3] , pred[2] , pred[3]]\n",
        "    conf = pred[4:]\n",
        "    label = np.argmax(conf)\n",
        "    max_conf = np.max(conf)\n",
        "    # print(np.max(conf))\n",
        "\n",
        "\n",
        "    boxes.append(box)\n",
        "    scores.append(max_conf)\n",
        "    class_ids.append(label)\n",
        "\n",
        "  result_boxes = cv2.dnn.NMSBoxes(boxes, scores, 0.25, 0.45, 0.5)\n",
        "\n",
        "  for i in range(len(result_boxes)):\n",
        "    index = result_boxes[i]\n",
        "    box = boxes[index]\n",
        "    detection = {\n",
        "            'class_id': class_ids[index],\n",
        "            # 'class_name': CLASSES[class_ids[index]],\n",
        "            'confidence': scores[index],\n",
        "            'box': box,\n",
        "            # 'scale': scale}\n",
        "    }\n",
        "    # detections.append(detection)\n",
        "    draw_detect(img, round(box[0]), round(box[1]),round(box[2]), round(box[3]),\n",
        "        scores[index] , class_ids[index])\n",
        "  cv2_imshow(img)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3durmcNST-ff",
        "outputId": "70b08e39-83a1-44f8-bde1-1a9ce0d48677"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorrt as trt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorrt as trt\n",
        "import torch.nn as nn\n",
        "\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
        "\n",
        "serialized_plan_fp32 = trt_file\n",
        "\n",
        "HEIGHT = 320\n",
        "WIDTH = 320\n",
        "\n",
        "img = cv2.imread(\"dog.jpeg\")\n",
        "img = cv2.resize(img , (WIDTH , HEIGHT))\n",
        "im = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "im = np.array(im, dtype=np.float32, order='C')\n",
        "im = im.transpose((2, 0, 1))\n",
        "im = (2.0 / 255.0) * im - 1.0\n",
        "\n",
        "engine = load_engine(trt_runtime, serialized_plan_fp32)\n",
        "h_input, d_input, h_output, d_output, stream = allocate_buffers(engine, 1, trt.float32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Wssv8LaKVYF_",
        "outputId": "7499e4de-1388-4afe-dd02-46b818462b2d"
      },
      "outputs": [],
      "source": [
        "out = do_inference(engine, im, h_input, d_input, h_output, d_output, stream, 1, HEIGHT, WIDTH)\n",
        "# cv2_imshow(img)\n",
        "show_detect(img , out)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
