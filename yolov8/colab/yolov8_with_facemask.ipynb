{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a7RBVllTOCd"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Ym_co7Wsl2"
      },
      "source": [
        "## training yolov8 with dogs and cats dataset\n",
        "\n",
        "https://www.kaggle.com/datasets/andrewmvd/dog-and-cat-detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt359aGMXSJ1"
      },
      "source": [
        "#### download dataset from ```https://github.com/sergiovirahonda/FaceMaskDataset/tree/main ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoRk8R2Ur6Ed",
        "outputId": "85f877b5-dd4a-40b5-9361-0ee6d2b64601"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/sergiovirahonda/FaceMaskDataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cud1hVoJYMXQ"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt8B0SCQdO-Y"
      },
      "source": [
        "#### CLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deXoZt6e-QE6",
        "outputId": "33198e0d-d8a8-4b55-a3cc-cad0a15e82be"
      },
      "outputs": [],
      "source": [
        "!yolo detect train data=/content/FaceMaskDataset/dataset.yaml model=yolov8n.pt epochs=10 imgsz=320"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGsraJRgdSwM"
      },
      "source": [
        "#### python test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS7Yk3bxdT2j",
        "outputId": "55370193-d0ff-41c1-f253-6a41763349fb"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt')\n",
        "model.predict(\"/content/FaceMaskDataset/images/train/0.jpg\", save=True, imgsz=320, conf=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orpE2xr2aRNm"
      },
      "source": [
        "## export yolov8 to trt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myLH8_0ND6GR"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "# your model path\n",
        "train_path = Path(\"/content/runs/detect/train\")\n",
        "model_path = train_path / \"weights\"\n",
        "pt_file = str(model_path / \"best.pt\")\n",
        "onnx_file = str(model_path / \"best.onnx\")\n",
        "trt_file = str(model_path / \"best.engine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kml-Warneajo"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download(train_path / \"results.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx8sSRFgYpCD",
        "outputId": "05a9cdc3-eb80-4a3e-d6b6-9824077aae1d"
      },
      "outputs": [],
      "source": [
        "!yolo export model={pt_file} format=onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uhrzUqWq9JrW",
        "outputId": "20a82901-7788-4752-972b-84e5b14e3fe6"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(onnx_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeyiJxKaWf2f"
      },
      "source": [
        "### onnx to trt engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r06djutgYtu",
        "outputId": "3bd4bc04-82eb-42a1-bbe3-c558d6a6c21d"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip install --upgrade tensorrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6Y8UGeZiUAz"
      },
      "outputs": [],
      "source": [
        "import tensorrt as trt\n",
        "\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
        "def build_engine(onnx_path, shape):\n",
        "\n",
        "   \"\"\"\n",
        "   This is the function to create the TensorRT engine\n",
        "   Args:\n",
        "      onnx_path : Path to onnx_file.\n",
        "      shape : Shape of the input of the ONNX file.\n",
        "  \"\"\"\n",
        "   with trt.Builder(TRT_LOGGER) as builder, builder.create_network(1) as network, builder.create_builder_config() as config, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
        "       config.max_workspace_size = (256 << 20)\n",
        "       with open(onnx_path, 'rb') as model:\n",
        "           parser.parse(model.read())\n",
        "       network.get_input(0).shape = shape\n",
        "       engine = builder.build_engine(network, config)\n",
        "       return engine\n",
        "\n",
        "def save_engine(engine, file_name):\n",
        "   buf = engine.serialize()\n",
        "   with open(file_name, 'wb') as f:\n",
        "       f.write(buf)\n",
        "def load_engine(trt_runtime, plan_path):\n",
        "  with open(plan_path, 'rb') as f:\n",
        "    engine_data = f.read()\n",
        "  engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
        "  # engine = trt_runtime.deserialize_cuda_engine(Path(plan_path).read_bytes())\n",
        "  return engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Quryc8b4ic0O",
        "outputId": "7f90a09f-029c-4c44-820b-b296123e12e0"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from onnx import ModelProto\n",
        "import tensorrt as trt\n",
        "\n",
        "engine_name = trt_file\n",
        "onnx_path = onnx_file\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "model = ModelProto()\n",
        "with open(onnx_path, \"rb\") as f:\n",
        "    model.ParseFromString(f.read())\n",
        "\n",
        "d0 = model.graph.input[0].type.tensor_type.shape.dim[1].dim_value\n",
        "d1 = model.graph.input[0].type.tensor_type.shape.dim[2].dim_value\n",
        "d2 = model.graph.input[0].type.tensor_type.shape.dim[3].dim_value\n",
        "shape = [batch_size , d0, d1 ,d2]\n",
        "engine = build_engine(onnx_path, shape= shape)\n",
        "save_engine(engine, engine_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9os3k9iqiJB",
        "outputId": "95dc0437-1058-4f45-de48-5fc4a860becd"
      },
      "outputs": [],
      "source": [
        "output_0 = model.graph.output[0].type.tensor_type.shape.dim[0].dim_value\n",
        "output_1 = model.graph.output[0].type.tensor_type.shape.dim[1].dim_value\n",
        "output_2 = model.graph.output[0].type.tensor_type.shape.dim[2].dim_value\n",
        "model_output_shape = (output_0 , output_1 , output_2)\n",
        "print(model_output_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMYRsUH0aWXs"
      },
      "source": [
        "## tensorRT inference yolov8 engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V08kVfTa4Pb",
        "outputId": "227c1447-4958-43fe-e2ca-acf710d8641b"
      },
      "outputs": [],
      "source": [
        "!pip install pycuda\n",
        "!wget https://images.livemint.com/img/2023/02/15/1600x900/face_masks_1676434071914_1676434072173_1676434072173.jpg -O ./people.jpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcyVovAMac-V"
      },
      "outputs": [],
      "source": [
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "\n",
        "def allocate_buffers(engine, batch_size, data_type):\n",
        "\n",
        "   \"\"\"\n",
        "   This is the function to allocate buffers for input and output in the device\n",
        "   Args:\n",
        "      engine : The path to the TensorRT engine.\n",
        "      batch_size : The batch size for execution time.\n",
        "      data_type: The type of the data for input and output, for example trt.float32.\n",
        "\n",
        "   Output:\n",
        "      h_input_1: Input in the host.\n",
        "      d_input_1: Input in the device.\n",
        "      h_output_1: Output in the host.\n",
        "      d_output_1: Output in the device.\n",
        "      stream: CUDA stream.\n",
        "\n",
        "   \"\"\"\n",
        "\n",
        "   # Determine dimensions and create page-locked memory buffers (which won't be swapped to disk) to hold host inputs/outputs.\n",
        "   h_input_1 = cuda.pagelocked_empty(batch_size * trt.volume(engine.get_binding_shape(0)), dtype=trt.nptype(data_type))\n",
        "   h_output = cuda.pagelocked_empty(batch_size * trt.volume(engine.get_binding_shape(1)), dtype=trt.nptype(data_type))\n",
        "   # Allocate device memory for inputs and outputs.\n",
        "   d_input_1 = cuda.mem_alloc(h_input_1.nbytes)\n",
        "\n",
        "   d_output = cuda.mem_alloc(h_output.nbytes)\n",
        "   # Create a stream in which to copy inputs/outputs and run inference.\n",
        "   stream = cuda.Stream()\n",
        "   return h_input_1, d_input_1, h_output, d_output, stream\n",
        "\n",
        "def load_images_to_buffer(pics, pagelocked_buffer):\n",
        "   preprocessed = np.asarray(pics).ravel()\n",
        "   np.copyto(pagelocked_buffer, preprocessed)\n",
        "\n",
        "def do_inference(engine, pics_1, h_input_1, d_input_1, h_output, d_output, stream, batch_size, height, width):\n",
        "   \"\"\"\n",
        "   This is the function to run the inference\n",
        "   Args:\n",
        "      engine : Path to the TensorRT engine\n",
        "      pics_1 : Input images to the model.\n",
        "      h_input_1: Input in the host\n",
        "      d_input_1: Input in the device\n",
        "      h_output_1: Output in the host\n",
        "      d_output_1: Output in the device\n",
        "      stream: CUDA stream\n",
        "      batch_size : Batch size for execution time\n",
        "      height: Height of the output image\n",
        "      width: Width of the output image\n",
        "\n",
        "   Output:\n",
        "      The list of output images\n",
        "\n",
        "   \"\"\"\n",
        "\n",
        "   load_images_to_buffer(pics_1, h_input_1)\n",
        "\n",
        "   with engine.create_execution_context() as context:\n",
        "      # Transfer input data to the GPU.\n",
        "      cuda.memcpy_htod_async(d_input_1, h_input_1, stream)\n",
        "\n",
        "      # Run inference.\n",
        "\n",
        "      context.profiler = trt.Profiler()\n",
        "      context.execute(batch_size=1, bindings=[int(d_input_1), int(d_output)])\n",
        "\n",
        "      # Transfer predictions back from the GPU.\n",
        "      cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
        "      # Synchronize the stream\n",
        "      stream.synchronize()\n",
        "      # Return the host output.\n",
        "      out = h_output.reshape((model_output_shape))\n",
        "      # out = h_output\n",
        "      return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8HnEuTpRr9S"
      },
      "outputs": [],
      "source": [
        "def draw_detect(img , x , y , width , height , conf , label):\n",
        "  # label = f'{CLASSES[class_id]} ({confidence:.2f})'\n",
        "  # color = colors[class_id]\n",
        "  print(x , y , width , height , conf , label)\n",
        "  cv2.rectangle(img, (x, y), (x + width, y + height), (0,0,255), 2)\n",
        "  cv2.putText(img, f\"{label} {conf}\", (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
        "\n",
        "def show_detect(img , preds , threshold = 0.5):\n",
        "  boxes = []\n",
        "  scores = []\n",
        "  class_ids = []\n",
        "\n",
        "  for pred_idx in range(preds.shape[2]):\n",
        "    pred = preds[0,:,pred_idx]\n",
        "    box = [pred[0] - 0.5*pred[2] , pred[1] - 0.5*pred[3] , pred[2] , pred[3]]\n",
        "    conf = pred[4:]\n",
        "    label = np.argmax(conf)\n",
        "    max_conf = np.max(conf)\n",
        "    # print(np.max(conf))\n",
        "\n",
        "\n",
        "    boxes.append(box)\n",
        "    scores.append(max_conf)\n",
        "    class_ids.append(label)\n",
        "\n",
        "  result_boxes = cv2.dnn.NMSBoxes(boxes, scores, 0.25, 0.45, 0.5)\n",
        "\n",
        "  for i in range(len(result_boxes)):\n",
        "    index = result_boxes[i]\n",
        "    box = boxes[index]\n",
        "    detection = {\n",
        "            'class_id': class_ids[index],\n",
        "            # 'class_name': CLASSES[class_ids[index]],\n",
        "            'confidence': scores[index],\n",
        "            'box': box,\n",
        "            # 'scale': scale}\n",
        "    }\n",
        "    # detections.append(detection)\n",
        "    draw_detect(img, round(box[0]), round(box[1]),round(box[2]), round(box[3]),\n",
        "        scores[index] , class_ids[index])\n",
        "  cv2_imshow(img)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3durmcNST-ff",
        "outputId": "730e6444-cee0-488b-cf87-09102ad2a0d1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorrt as trt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorrt as trt\n",
        "import torch.nn as nn\n",
        "\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
        "\n",
        "serialized_plan_fp32 = trt_file\n",
        "\n",
        "HEIGHT = 320\n",
        "WIDTH = 320\n",
        "\n",
        "img = cv2.imread(\"/content/people.jpeg\")\n",
        "img = cv2.resize(img , (WIDTH , HEIGHT))\n",
        "im = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "im = np.array(im, dtype=np.float32, order='C')\n",
        "im = im.transpose((2, 0, 1))\n",
        "im = (2.0 / 255.0) * im - 1.0\n",
        "\n",
        "engine = load_engine(trt_runtime, serialized_plan_fp32)\n",
        "h_input, d_input, h_output, d_output, stream = allocate_buffers(engine, 1, trt.float32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "Wssv8LaKVYF_",
        "outputId": "92a78e10-5145-45d3-8712-99658d0ed415"
      },
      "outputs": [],
      "source": [
        "out = do_inference(engine, im, h_input, d_input, h_output, d_output, stream, 1, HEIGHT, WIDTH)\n",
        "# cv2_imshow(img)\n",
        "show_detect(img , out)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
