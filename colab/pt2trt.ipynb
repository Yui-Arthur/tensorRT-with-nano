{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "XwgW3LLmsAA4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pt -> onnx -> trt"
      ],
      "metadata": {
        "id": "j2EbNkkuuunP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pytoch model to onnx model"
      ],
      "metadata": {
        "id": "tCzaBN5fnMBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "id": "4XdXbPAInnu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2wb7wsRS-3e",
        "outputId": "9ab7e845-86ae-4c9d-eb26-e42df6131d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torch.onnx\n",
        "\n",
        "\n",
        "model = torchvision.models.resnet50(weights = \"ResNet50_Weights.IMAGENET1K_V2\")\n",
        "model.eval()\n",
        "# Input to the model\n",
        "batch_size = 1\n",
        "x = torch.randn(batch_size, 3, 224, 224, requires_grad=True)\n",
        "torch_out = model(x)\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model,# model being run\n",
        "        x,   # model input (or a tuple for multiple inputs)\n",
        "        \"resnet50.onnx\",  # where to save the model (can be a file or file-like object)\n",
        "        export_params=True, # store the trained parameter weights inside the model file\n",
        "        opset_version=10,   # the ONNX version to export the model to\n",
        "        do_constant_folding=True, # whether to execute constant folding for optimization\n",
        "        input_names = ['input'],  # the model's input names\n",
        "        output_names = ['output'], # the model's output names\n",
        "        dynamic_axes={'input' : {0 : 'batch_size'}, # variable length axes\n",
        "              'output' : {0 : 'batch_size'}})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### onnx model to trt engine"
      ],
      "metadata": {
        "id": "uDgEa3Xon76w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install --upgrade tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiIsOqcQn64n",
        "outputId": "3afc4b85-2668-4584-d76e-682ee2a4b749"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorrt in /usr/local/lib/python3.10/dist-packages (8.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt as trt\n",
        "\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
        "def build_engine(onnx_path, shape = [1,224,224,3]):\n",
        "\n",
        "   \"\"\"\n",
        "   This is the function to create the TensorRT engine\n",
        "   Args:\n",
        "      onnx_path : Path to onnx_file.\n",
        "      shape : Shape of the input of the ONNX file.\n",
        "  \"\"\"\n",
        "   with trt.Builder(TRT_LOGGER) as builder, builder.create_network(1) as network, builder.create_builder_config() as config, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
        "       config.max_workspace_size = (256 << 20)\n",
        "       with open(onnx_path, 'rb') as model:\n",
        "           parser.parse(model.read())\n",
        "       network.get_input(0).shape = shape\n",
        "       engine = builder.build_engine(network, config)\n",
        "       return engine\n",
        "\n",
        "def save_engine(engine, file_name):\n",
        "   buf = engine.serialize()\n",
        "   with open(file_name, 'wb') as f:\n",
        "       f.write(buf)\n",
        "def load_engine(trt_runtime, plan_path):\n",
        "   with open(plan_path, 'rb') as f:\n",
        "       engine_data = f.read()\n",
        "   engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
        "   return engine"
      ],
      "metadata": {
        "id": "i5hV5B3romRx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from onnx import ModelProto\n",
        "import tensorrt as trt\n",
        "\n",
        "engine_name = \"resnet50.trt\"\n",
        "onnx_path = \"./resnet50.onnx\"\n",
        "batch_size = 1\n",
        "\n",
        "model = ModelProto()\n",
        "with open(onnx_path, \"rb\") as f:\n",
        "    model.ParseFromString(f.read())\n",
        "\n",
        "d0 = model.graph.input[0].type.tensor_type.shape.dim[1].dim_value\n",
        "d1 = model.graph.input[0].type.tensor_type.shape.dim[2].dim_value\n",
        "d2 = model.graph.input[0].type.tensor_type.shape.dim[3].dim_value\n",
        "shape = [batch_size , d0, d1 ,d2]\n",
        "engine = build_engine(onnx_path, shape= shape)\n",
        "save_engine(engine, engine_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p34NqAOsog2J",
        "outputId": "5894bd0a-dbff-4497-dcab-59c758ee7875"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-d5c2a7eeabb5>:14: DeprecationWarning: Use set_memory_pool_limit instead.\n",
            "  config.max_workspace_size = (256 << 20)\n",
            "<ipython-input-11-d5c2a7eeabb5>:18: DeprecationWarning: Use build_serialized_network instead.\n",
            "  engine = builder.build_engine(network, config)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### trt inference"
      ],
      "metadata": {
        "id": "ajl4-x4CrDY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda\n",
        "!wget https://www.akc.org/wp-content/uploads/2021/07/Cavalier-King-Charles-Spaniel-laying-down-indoors.jpeg -O ./dog.jpeg\n",
        "!wget https://www.collinsdictionary.com/images/full/hen_151155842.jpg -O ./hen.jpg"
      ],
      "metadata": {
        "id": "6k0mkTN4rlnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "\n",
        "def allocate_buffers(engine, batch_size, data_type):\n",
        "\n",
        "   \"\"\"\n",
        "   This is the function to allocate buffers for input and output in the device\n",
        "   Args:\n",
        "      engine : The path to the TensorRT engine.\n",
        "      batch_size : The batch size for execution time.\n",
        "      data_type: The type of the data for input and output, for example trt.float32.\n",
        "\n",
        "   Output:\n",
        "      h_input_1: Input in the host.\n",
        "      d_input_1: Input in the device.\n",
        "      h_output_1: Output in the host.\n",
        "      d_output_1: Output in the device.\n",
        "      stream: CUDA stream.\n",
        "\n",
        "   \"\"\"\n",
        "\n",
        "   # Determine dimensions and create page-locked memory buffers (which won't be swapped to disk) to hold host inputs/outputs.\n",
        "   h_input_1 = cuda.pagelocked_empty(batch_size * trt.volume(engine.get_binding_shape(0)), dtype=trt.nptype(data_type))\n",
        "   h_output = cuda.pagelocked_empty(batch_size * trt.volume(engine.get_binding_shape(1)), dtype=trt.nptype(data_type))\n",
        "   # Allocate device memory for inputs and outputs.\n",
        "   d_input_1 = cuda.mem_alloc(h_input_1.nbytes)\n",
        "\n",
        "   d_output = cuda.mem_alloc(h_output.nbytes)\n",
        "   # Create a stream in which to copy inputs/outputs and run inference.\n",
        "   stream = cuda.Stream()\n",
        "   return h_input_1, d_input_1, h_output, d_output, stream\n",
        "\n",
        "def load_images_to_buffer(pics, pagelocked_buffer):\n",
        "   preprocessed = np.asarray(pics).ravel()\n",
        "   np.copyto(pagelocked_buffer, preprocessed)\n",
        "\n",
        "def do_inference(engine, pics_1, h_input_1, d_input_1, h_output, d_output, stream, batch_size, height, width):\n",
        "   \"\"\"\n",
        "   This is the function to run the inference\n",
        "   Args:\n",
        "      engine : Path to the TensorRT engine\n",
        "      pics_1 : Input images to the model.\n",
        "      h_input_1: Input in the host\n",
        "      d_input_1: Input in the device\n",
        "      h_output_1: Output in the host\n",
        "      d_output_1: Output in the device\n",
        "      stream: CUDA stream\n",
        "      batch_size : Batch size for execution time\n",
        "      height: Height of the output image\n",
        "      width: Width of the output image\n",
        "\n",
        "   Output:\n",
        "      The list of output images\n",
        "\n",
        "   \"\"\"\n",
        "\n",
        "   load_images_to_buffer(pics_1, h_input_1)\n",
        "\n",
        "   with engine.create_execution_context() as context:\n",
        "      # Transfer input data to the GPU.\n",
        "      cuda.memcpy_htod_async(d_input_1, h_input_1, stream)\n",
        "\n",
        "      # Run inference.\n",
        "\n",
        "      context.profiler = trt.Profiler()\n",
        "      context.execute(batch_size=1, bindings=[int(d_input_1), int(d_output)])\n",
        "\n",
        "      # Transfer predictions back from the GPU.\n",
        "      cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
        "      # Synchronize the stream\n",
        "      stream.synchronize()\n",
        "      # Return the host output.\n",
        "      # out = h_output.reshape((batch_size, -1, height, width))\n",
        "      out = h_output\n",
        "      return out.reshape(1, -1)\n",
        "def softmax(x):\n",
        "  # x -= np.max(x , axis=1 , keepdims = True)\n",
        "  x = np.exp(x) / np.sum(np.exp(x) , axis=1 , keepdims = True)\n",
        "  return x"
      ],
      "metadata": {
        "id": "jOIYwMQBrIWs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import keras\n",
        "import tensorrt as trt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorrt as trt\n",
        "import torch.nn as nn\n",
        "# import labels  # from cityscapes evaluation script\n",
        "# import skimage.transform\n",
        "\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
        "\n",
        "input_file_path = \"hen.jpg\"\n",
        "serialized_plan_fp32 = \"resnet50.trt\"\n",
        "HEIGHT = 224\n",
        "WIDTH = 224\n",
        "\n",
        "img = Image.open(input_file_path).resize((WIDTH , HEIGHT))\n",
        "# img.show()\n",
        "img = np.asarray(img)\n",
        "im = np.array(img, dtype=np.float32, order='C')\n",
        "im = im.transpose((2, 0, 1))\n",
        "im = (2.0 / 255.0) * im - 1.0\n",
        "\n",
        "engine = load_engine(trt_runtime, serialized_plan_fp32)\n",
        "h_input, d_input, h_output, d_output, stream = allocate_buffers(engine, 1, trt.float32)\n",
        "\n",
        "\n",
        "out = do_inference(engine, im, h_input, d_input, h_output, d_output, stream, 1, HEIGHT, WIDTH)\n",
        "out = softmax(out)\n",
        "\n",
        "label = np.argmax(out)\n",
        "value = np.max(out)\n",
        "\n",
        "print(label , value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJpZUTr6rLSm",
        "outputId": "a8d6fa30-b726-4de5-d1e5-37f30e9146a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 0.5181372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-fc77fe6cee0c>:25: DeprecationWarning: Use get_tensor_shape instead.\n",
            "  h_input_1 = cuda.pagelocked_empty(batch_size * trt.volume(engine.get_binding_shape(0)), dtype=trt.nptype(data_type))\n",
            "<ipython-input-14-fc77fe6cee0c>:26: DeprecationWarning: Use get_tensor_shape instead.\n",
            "  h_output = cuda.pagelocked_empty(batch_size * trt.volume(engine.get_binding_shape(1)), dtype=trt.nptype(data_type))\n",
            "<ipython-input-14-fc77fe6cee0c>:68: DeprecationWarning: Use execute_v2 instead.\n",
            "  context.execute(batch_size=1, bindings=[int(d_input_1), int(d_output)])\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: pagelocked_host_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: stream in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch2trt"
      ],
      "metadata": {
        "id": "96M8TJvvu1uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime\n",
        "!wget https://www.akc.org/wp-content/uploads/2021/07/Cavalier-King-Charles-Spaniel-laying-down-indoors.jpeg -O ./dog.jpeg\n",
        "!wget https://www.collinsdictionary.com/images/full/hen_151155842.jpg -O ./hen.jpg"
      ],
      "metadata": {
        "id": "bZTWov5s3spG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install --upgrade tensorrt\n",
        "!git clone https://github.com/NVIDIA-AI-IOT/torch2trt\n",
        "%cd torch2trt\n",
        "!python setup.py install\n",
        "# !cmake -B build . && cmake --build build --target install && ldconfig\n",
        "%cd ..\n"
      ],
      "metadata": {
        "id": "jIft7Eoeu7ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 要重啟才能使用"
      ],
      "metadata": {
        "id": "Nkl1KRhz80FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os._exit(00)"
      ],
      "metadata": {
        "id": "4Hmg6yqaxUJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch2trt import torch2trt\n",
        "import torchvision\n",
        "\n",
        "\n",
        "# create some regular pytorch model...\n",
        "model = torchvision.models.resnet50(weights = \"ResNet50_Weights.IMAGENET1K_V2\")\n",
        "model.eval().cuda()\n",
        "# Input to the model\n",
        "batch_size = 1\n",
        "x = torch.randn(batch_size, 3, 224, 224, requires_grad=True).cuda()\n",
        "\n",
        "# convert to TensorRT feeding sample data as input\n",
        "model_trt = torch2trt(model, [x])\n"
      ],
      "metadata": {
        "id": "pD4xOI5PwLuf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "input_file_path = \"hen.jpg\"\n",
        "img = Image.open(input_file_path)\n",
        "\n",
        "tfm = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "img = tfm(img).cuda()\n",
        "\n",
        "pred = model_trt(img).to(\"cpu\")\n",
        "softmax = nn.Softmax(dim=1)\n",
        "pred = softmax(pred)\n",
        "# print(pred)\n",
        "label = torch.argmax(pred)\n",
        "conf = torch.max(pred)\n",
        "print(label , conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSy5-4R_j_A-",
        "outputId": "d0202510-dbae-4bb8-f37d-917a2b53d2a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8) tensor(0.5346)\n"
          ]
        }
      ]
    }
  ]
}