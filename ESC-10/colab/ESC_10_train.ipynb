{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ESC-10 Dataset"
      ],
      "metadata": {
        "id": "8B2i69fiHqX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/u/0/uc?id=1ioAloEiizmkS1Up6NpwPvv3LzWY2BKGZ&export=download"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSiLg7rYah6C",
        "outputId": "ff3d824d-fda7-45ad-d000-c174a9b7b132"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1ioAloEiizmkS1Up6NpwPvv3LzWY2BKGZ\n",
            "To: /content/esc_classification_nuk.zip\n",
            "100% 150M/150M [00:01<00:00, 106MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/esc_classification_nuk.zip"
      ],
      "metadata": {
        "id": "EJ2j0aCdap1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3218457-fbdb-4e03-ede3-5d33c1637ba0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/esc_classification_nuk.zip\n",
            "replace esc_classification_nuk/code/Predictor.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocess"
      ],
      "metadata": {
        "id": "Z5x37JFPH1fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PrepareDataset(dataDir:str, batchSize:int=10) -> dict:\n",
        "  \"\"\"\n",
        "  Prepare the training and validation dataset with tf.data.Dataset.\n",
        "\n",
        "  Args:\n",
        "      dataDir: The directory of data.\n",
        "      batchSize: Number of samples in a batch.\n",
        "  Returns:\n",
        "      A dictionary of training and validation dataset.\n",
        "  \"\"\"\n",
        "\n",
        "  ## Get class index dictionary\n",
        "  subsetDirInfo = {\"train\":pathlib.Path(dataDir)/\"train\", \"valid\":pathlib.Path(dataDir)/\"valid\"}\n",
        "  classes = sorted([each.name for each in subsetDirInfo[\"train\"].glob(\"*\")])\n",
        "  classInfo = dict(zip(classes,range(len(classes))))\n",
        "\n",
        "  ## Get file paths and labels\n",
        "  paths = {\"train\":list(), \"valid\":list()}\n",
        "  labels = {\"train\":list(), \"valid\":list()}\n",
        "  for eachSet, eachDir in subsetDirInfo.items():\n",
        "      for eachPath in eachDir.rglob(\"*\"):\n",
        "          if eachPath.is_file():\n",
        "              paths[eachSet].append(str(eachPath))\n",
        "              labels[eachSet].append(classInfo[eachPath.parts[-2]])\n",
        "\n",
        "  ## Build tf.data.Dataset\n",
        "  dataset = {\"class_indices\": classInfo}\n",
        "  reader = lambda x, y: [tf.audio.decode_wav(tf.io.read_file(x))[0], tf.one_hot(y, len(classInfo))]\n",
        "  for eachSet in subsetDirInfo.keys():\n",
        "      eachTFData = tf.data.Dataset.from_tensor_slices((paths[eachSet],labels[eachSet]))\n",
        "      dataset.update({eachSet:eachTFData})\n",
        "      dataset[eachSet] = dataset[eachSet].shuffle(len(paths[eachSet]), reshuffle_each_iteration=True)\n",
        "      dataset[eachSet] = dataset[eachSet].map(reader, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      dataset[eachSet] = dataset[eachSet].batch(batchSize, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "B73HApUUH1Bo"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model"
      ],
      "metadata": {
        "id": "13wJXN3OHtT_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "WeI7Cj1BZ0_O"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pathlib, json\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Generate a new model with loss function and optimizer, and provide training and validation steps.\n",
        "    \"\"\"\n",
        "    def __init__(self, xSize:tuple, ySize:tuple, modelInfo:dict):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            xSize: Input data size. Ex. (44100, 2) for the stereo audio.\n",
        "            ySize: Output data size. Ex. (10,) for 10 classes.\n",
        "            modelInfo: Model parameters information.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self._xSize = xSize\n",
        "        self._ySize = ySize\n",
        "        self._modelInfo = modelInfo\n",
        "        self._model = self._BuildModel()\n",
        "        self._learner = self._BuildLearner()\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x:tf.Tensor, training:bool=False) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        Defines activities when the model is called (or called by `__call__`).\n",
        "\n",
        "        Args:\n",
        "            x: A batch of input data.\n",
        "            training: Training (True) or inferencing (False) mode.\n",
        "        Returns:\n",
        "            Output of the model.\n",
        "        \"\"\"\n",
        "        output = self._model(x, training=training)\n",
        "\n",
        "        return output\n",
        "\n",
        "    @tf.function\n",
        "    def Train(self, x:tf.Tensor, y:tf.Tensor):\n",
        "        \"\"\"\n",
        "        Train the model once with a batch data of input `x` and target `y`.\n",
        "\n",
        "        Args:\n",
        "            x: A batch of input data.\n",
        "            y: A batch of target data.\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = self.__call__(x, training=True)\n",
        "            classLoss = self._learner[\"get_loss\"](output, y)\n",
        "        cGradients = tape.gradient(classLoss, self._model.trainable_variables)\n",
        "        self._learner[\"optimize\"].apply_gradients(zip(cGradients, self._model.trainable_variables))\n",
        "\n",
        "    @tf.function\n",
        "    def Validate(self, x:tf.Tensor, y:tf.Tensor) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        Validate the model once with a batch data of input `x` and target `y`.\n",
        "\n",
        "        Args:\n",
        "            x: A batch of input data.\n",
        "            y: A batch of target data.\n",
        "        Returns:\n",
        "            The performance value.\n",
        "        \"\"\"\n",
        "        output = self.__call__(x, training=False)\n",
        "        review = tf.math.in_top_k(tf.math.argmax(y,axis=1), output, 1)\n",
        "        perf = tf.math.reduce_mean(tf.cast(review, dtype=\"float32\"))\n",
        "\n",
        "        return perf\n",
        "\n",
        "    def _BuildModel(self) -> tf.keras.Model:\n",
        "        \"\"\"\n",
        "        Build the NN model.\n",
        "\n",
        "        Returns:\n",
        "            A Keras model instance.\n",
        "        \"\"\"\n",
        "        inputTensor = tf.keras.Input(shape=self._xSize)\n",
        "        featureMap = inputTensor\n",
        "        featureMap = tf.keras.layers.Conv1D(32, [9], strides=[8], padding=\"same\", use_bias=False)(featureMap)\n",
        "        featureMap = tf.keras.layers.BatchNormalization()(featureMap)\n",
        "        featureMap = tf.keras.layers.ReLU()(featureMap)\n",
        "        featureMap = tf.keras.layers.Conv1D(64, [9], strides=[8], padding=\"same\", use_bias=False)(featureMap)\n",
        "        featureMap = tf.keras.layers.BatchNormalization()(featureMap)\n",
        "        featureMap = tf.keras.layers.ReLU()(featureMap)\n",
        "        featureMap = tf.keras.layers.Conv1D(128, [3], strides=[2], padding=\"same\", use_bias=False)(featureMap)\n",
        "        featureMap = tf.keras.layers.BatchNormalization()(featureMap)\n",
        "        featureMap = tf.keras.layers.ReLU()(featureMap)\n",
        "        featureMap = tf.keras.layers.Conv1D(256, [3], strides=[2], padding=\"same\", use_bias=False)(featureMap)\n",
        "        featureMap = tf.keras.layers.BatchNormalization()(featureMap)\n",
        "        featureMap = tf.keras.layers.ReLU()(featureMap)\n",
        "        featureMap = tf.keras.layers.Conv1D(512, [3], strides=[2], padding=\"same\", use_bias=False)(featureMap)\n",
        "        featureMap = tf.keras.layers.BatchNormalization()(featureMap)\n",
        "        featureMap = tf.keras.layers.ReLU()(featureMap)\n",
        "        featureMap = tf.keras.layers.Conv1D(1024, [3], strides=[2], padding=\"same\", use_bias=False)(featureMap)\n",
        "        featureMap = tf.keras.layers.BatchNormalization()(featureMap)\n",
        "        featureMap = tf.keras.layers.ReLU()(featureMap)\n",
        "        embedding = tf.keras.layers.GlobalAveragePooling1D()(featureMap)\n",
        "        embedding = tf.keras.layers.Dropout(rate=self._modelInfo[\"dropout\"])(embedding)\n",
        "        outputTensor = tf.keras.layers.Dense(units=self._ySize[-1], activation=\"softmax\")(embedding)\n",
        "        model = tf.keras.Model(inputTensor, outputTensor)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _BuildLearner(self) -> dict:\n",
        "        \"\"\"\n",
        "        Build loss functions and optimizers.\n",
        "\n",
        "        Returns:\n",
        "            A dictionary of loss function and optimizer.\n",
        "        \"\"\"\n",
        "        classLoss = lambda p, y: tf.reduce_mean(-tf.reduce_sum(y*tf.math.log(p+1e-13), axis=1))\n",
        "        classOptimizer = tf.keras.optimizers.Adam(learning_rate=self._modelInfo[\"learning_rate\"])\n",
        "        learner = {\"get_loss\": classLoss, \"optimize\": classOptimizer}\n",
        "\n",
        "        return learner\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "NAQmsD-8H-at"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Basic CNN model training for audio classification.\n",
        "\"\"\"\n",
        "## Configuration\n",
        "dataDir = r\"/content/esc_classification_nuk/data/esc10\"\n",
        "batchSize = 10\n",
        "xSize = (44100*5, 1)\n",
        "ySize = (10,)\n",
        "epochs = 26\n",
        "newModel = r\"./model/test\"\n",
        "dropout = 0.2\n",
        "learningRate = 1e-4\n",
        "\n",
        "print(\"Preparing dataset...\")\n",
        "dataset = PrepareDataset(dataDir, batchSize=batchSize)\n",
        "\n",
        "print(\"Build the NN model...\")\n",
        "modelInfo = {\"dropout\": dropout, \"learning_rate\": learningRate}\n",
        "myModel = MyModel(xSize, ySize, modelInfo)\n",
        "\n",
        "\n",
        "print(\"Start training...\")\n",
        "for epoch in range(epochs):\n",
        "    perfDict = {\"train\":[], \"valid\":[]}\n",
        "    for inData, outData in dataset[\"train\"]:\n",
        "        myModel.Train(inData, outData)\n",
        "        # break\n",
        "    for inData, outData in dataset[\"train\"]:\n",
        "        perfDict[\"train\"].append(myModel.Validate(inData, outData))\n",
        "        # break\n",
        "    for inData, outData in dataset[\"valid\"]:\n",
        "        perfDict[\"valid\"].append(myModel.Validate(inData, outData))\n",
        "        # break\n",
        "    trainPerf = tf.math.reduce_mean(perfDict[\"train\"]) * 100\n",
        "    validPerf = tf.math.reduce_mean(perfDict[\"valid\"]) * 100\n",
        "    print(f\"Epoch: {epoch},    Train perf: {trainPerf:.2f},    Valid perf: {validPerf:.2f}\")\n",
        "\n",
        "print(\"Export the model and information...\")\n",
        "newModel = pathlib.Path(newModel)\n",
        "myModel.save(newModel/\"model\", include_optimizer=False)\n",
        "with open(newModel/\"class_info.json\", \"w\") as wFile:\n",
        "    json.dump(dataset[\"class_indices\"], wFile, indent=4)\n",
        "\n",
        "print(\"Completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQoTTHItH-40",
        "outputId": "19bb4ff9-12fb-4141-c187-39d8ee84fbea"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset...\n",
            "Build the NN model...\n",
            "Start training...\n",
            "Epoch: 0,    Train perf: 10.94,    Valid perf: 13.75\n",
            "Epoch: 1,    Train perf: 10.62,    Valid perf: 12.50\n",
            "Epoch: 2,    Train perf: 11.88,    Valid perf: 13.75\n",
            "Epoch: 3,    Train perf: 10.00,    Valid perf: 10.00\n",
            "Epoch: 4,    Train perf: 10.00,    Valid perf: 10.00\n",
            "Epoch: 5,    Train perf: 10.62,    Valid perf: 10.00\n",
            "Epoch: 6,    Train perf: 12.81,    Valid perf: 11.25\n",
            "Epoch: 7,    Train perf: 15.31,    Valid perf: 16.25\n",
            "Epoch: 8,    Train perf: 22.81,    Valid perf: 22.50\n",
            "Epoch: 9,    Train perf: 20.62,    Valid perf: 22.50\n",
            "Epoch: 10,    Train perf: 21.25,    Valid perf: 25.00\n",
            "Epoch: 11,    Train perf: 27.19,    Valid perf: 31.25\n",
            "Epoch: 12,    Train perf: 29.06,    Valid perf: 33.75\n",
            "Epoch: 13,    Train perf: 46.25,    Valid perf: 42.50\n",
            "Epoch: 14,    Train perf: 47.19,    Valid perf: 51.25\n",
            "Epoch: 15,    Train perf: 57.50,    Valid perf: 52.50\n",
            "Epoch: 16,    Train perf: 63.75,    Valid perf: 52.50\n",
            "Epoch: 17,    Train perf: 67.50,    Valid perf: 56.25\n",
            "Epoch: 18,    Train perf: 66.25,    Valid perf: 51.25\n",
            "Epoch: 19,    Train perf: 72.50,    Valid perf: 51.25\n",
            "Epoch: 20,    Train perf: 82.19,    Valid perf: 63.75\n",
            "Epoch: 21,    Train perf: 83.12,    Valid perf: 65.00\n",
            "Epoch: 22,    Train perf: 88.75,    Valid perf: 76.25\n",
            "Epoch: 23,    Train perf: 89.37,    Valid perf: 71.25\n",
            "Epoch: 24,    Train perf: 90.94,    Valid perf: 76.25\n",
            "Epoch: 25,    Train perf: 86.56,    Valid perf: 62.50\n",
            "Export the model and information...\n",
            "Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(xSize, ySize, modelInfo)\n",
        "model.build((1,220500,1))\n",
        "print(model._model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY9KLD_lLOEc",
        "outputId": "2e13ffa4-eb57-4af7-9d62-ea81a658798c"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_59 (InputLayer)       [(None, 220500, 1)]       0         \n",
            "                                                                 \n",
            " conv1d_118 (Conv1D)         (None, 27563, 32)         288       \n",
            "                                                                 \n",
            " batch_normalization_108 (B  (None, 27563, 32)         128       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_108 (ReLU)            (None, 27563, 32)         0         \n",
            "                                                                 \n",
            " conv1d_119 (Conv1D)         (None, 3446, 64)          18432     \n",
            "                                                                 \n",
            " batch_normalization_109 (B  (None, 3446, 64)          256       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_109 (ReLU)            (None, 3446, 64)          0         \n",
            "                                                                 \n",
            " conv1d_120 (Conv1D)         (None, 1723, 128)         24576     \n",
            "                                                                 \n",
            " batch_normalization_110 (B  (None, 1723, 128)         512       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_110 (ReLU)            (None, 1723, 128)         0         \n",
            "                                                                 \n",
            " conv1d_121 (Conv1D)         (None, 862, 256)          98304     \n",
            "                                                                 \n",
            " batch_normalization_111 (B  (None, 862, 256)          1024      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_111 (ReLU)            (None, 862, 256)          0         \n",
            "                                                                 \n",
            " conv1d_122 (Conv1D)         (None, 431, 512)          393216    \n",
            "                                                                 \n",
            " batch_normalization_112 (B  (None, 431, 512)          2048      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_112 (ReLU)            (None, 431, 512)          0         \n",
            "                                                                 \n",
            " conv1d_123 (Conv1D)         (None, 216, 1024)         1572864   \n",
            "                                                                 \n",
            " batch_normalization_113 (B  (None, 216, 1024)         4096      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_113 (ReLU)            (None, 216, 1024)         0         \n",
            "                                                                 \n",
            " global_average_pooling1d_3  (None, 1024)              0         \n",
            " 4 (GlobalAveragePooling1D)                                      \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2125994 (8.11 MB)\n",
            "Trainable params: 2121962 (8.09 MB)\n",
            "Non-trainable params: 4032 (15.75 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model"
      ],
      "metadata": {
        "id": "48M2NdoFHkRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "\n",
        "class Predictor:\n",
        "    \"\"\"\n",
        "    Inferencing interface of model.\n",
        "    \"\"\"\n",
        "    def __init__(self, modelPath:str):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            modelPath: Path of the model.\n",
        "        \"\"\"\n",
        "        self.__model = tf.keras.models.load_model(modelPath+\"/model\", compile=False)\n",
        "        with open(modelPath+\"/class_info.json\", \"r\") as rFile:\n",
        "            self.__classInfo = json.loads(rFile.read())\n",
        "            self.__classInfo = {value:key for key, value in self.__classInfo.items()}\n",
        "\n",
        "    def __call__(self, path:str) -> str:\n",
        "        \"\"\"\n",
        "        Read the file and make an inference.\n",
        "\n",
        "        Args:\n",
        "            path: A file path.\n",
        "        Returns:\n",
        "            A class name result.\n",
        "        \"\"\"\n",
        "        inputData = tf.expand_dims(tf.audio.decode_wav(tf.io.read_file(path))[0], 0)\n",
        "        pred = self.__model(inputData,training=False)\n",
        "        output = tf.squeeze(tf.argmax(self.__model(inputData,training=False), axis=1)).numpy()\n",
        "\n",
        "        result = self.__classInfo[output]\n",
        "\n",
        "        return pred[0][output].numpy() , result\n",
        "\n",
        "\n",
        "audioPath = r\"/content/esc_classification_nuk/data/esc10/valid/helicopter/5-177957-A-40.wav\" #.replace(\"\\\\\",\"/\")\n",
        "predictor = Predictor(modelPath=\"/content/model/test/\") #.replace(\"\\\\\",\"/\"))\n",
        "print(predictor(audioPath))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFGWOyolc_kR",
        "outputId": "82270db9-e4b3-4c6b-a11d-152efbca32b1"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_120580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.94573957, 'rooster')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export Model"
      ],
      "metadata": {
        "id": "M10gky25IDIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tf2onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGneioihJn18",
        "outputId": "75441564-f051-4274-9189-3100d11310b9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.10/dist-packages (1.15.1)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.23.5)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (23.5.26)\n",
            "Requirement already satisfied: protobuf~=3.20.2 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.4.1->tf2onnx) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m tf2onnx.convert --saved-model \"/content/model/test/model/\" --output \"./bs10_l4_d2.onnx\" --opset 12 --inputs input_1:0[1,220500,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z4En0WjIGi6",
        "outputId": "87aead9e-f58c-4d40-8d80-97c9768ab79a"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-21 11:50:46.279392: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2023-10-21 11:50:48.944885: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-10-21 11:50:48,945 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2023-10-21 11:50:49,278 - WARNING - Importing a function (__inference_internal_grad_fn_120580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "2023-10-21 11:50:50,306 - INFO - Signatures found in model: [serving_default].\n",
            "2023-10-21 11:50:50,306 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
            "2023-10-21 11:50:50,306 - INFO - Output names: ['output_1']\n",
            "2023-10-21 11:50:50,306 - WARNING - Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
            "2023-10-21 11:50:50,738 - INFO - Using tensorflow=2.13.0, onnx=1.14.1, tf2onnx=1.15.1/37820d\n",
            "2023-10-21 11:50:50,738 - INFO - Using opset <onnx, 12>\n",
            "2023-10-21 11:50:50,771 - INFO - Apply shape override:\n",
            "2023-10-21 11:50:50,772 - INFO - \tSet input_1:0 shape to [1, 220500, 1]\n",
            "2023-10-21 11:50:50,804 - INFO - Computed 0 values for constant folding\n",
            "2023-10-21 11:50:50,882 - INFO - Optimizing ONNX model\n",
            "2023-10-21 11:50:51,023 - INFO - After optimization: Const -6 (27->21), GlobalAveragePool +1 (0->1), Identity -2 (2->0), ReduceMean -1 (1->0), Reshape +1 (0->1), Squeeze +1 (6->7), Transpose -12 (12->0)\n",
            "2023-10-21 11:50:51,034 - INFO - \n",
            "2023-10-21 11:50:51,034 - INFO - Successfully converted TensorFlow model /content/model/test/model/ to ONNX\n",
            "2023-10-21 11:50:51,034 - INFO - Model inputs: ['input_1:0']\n",
            "2023-10-21 11:50:51,034 - INFO - Model outputs: ['output_1']\n",
            "2023-10-21 11:50:51,034 - INFO - ONNX model is saved at ./bs10_l4_d2.onnx\n"
          ]
        }
      ]
    }
  ]
}